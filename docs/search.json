[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Series de Tiempo",
    "section": "",
    "text": "Prefacio\nNotas computacionales de clase para el curso CA0415, Series de Tiempo.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "box_jenk.html",
    "href": "box_jenk.html",
    "title": "1  Enfoque de Box-Jenkins",
    "section": "",
    "text": "1.1 Ejemplos de series temporales\nSerie de tiempo de Johnson & Johnson\njj_tibble &lt;- tk_tbl(jj)\njj_tibble %&gt;% \n  ggplot(aes(x = index, y = value)) +\n  geom_line() +\n  labs(x = \"Tiempo\", y = \"Ganancia\")+\n  theme_bw()\nSerie de tiempo de temperaturas globales\ntemp_tibble &lt;- tk_tbl(gtemp_both)\ntemp_tibble %&gt;% \n  ggplot(aes(x = index, y = value)) +\n  geom_line() +\n  labs(x = \"Tiempo\", y = \"Anomalías de Temp.\")+\n  theme_bw()\nSerie de tiempo del índice de Dow Jones:\ndjia_tibble &lt;- tk_tbl(djia)\ndjia_tibble %&gt;% \n  select(index,Close) %&gt;%\n  ggplot(aes(x = index, y = Close)) +\n  geom_line() +\n  labs(x = \"Tiempo\", y = \"Precio de Cierre\")+\n  theme_bw()\nY después de calcular los log-retornos:\ndjiar &lt;- diff(log(djia$Close))[-1]\ndjiar_tibble &lt;- tk_tbl(djiar)\ndjiar_tibble  %&gt;% \n  select(index,Close) %&gt;%\n  ggplot(aes(x = index, y = Close)) +\n  geom_line() +\n  labs(x = \"Tiempo\", y = \"Precio de Cierre\")+\n  theme_bw()\nSerie de tiempo del Niño y la población de peces:\nsoi_tibble &lt;- tk_tbl(soi) %&gt;% rename(soi = value)\n\nsoi_tsibble &lt;- soi_tibble %&gt;% mutate(index = yearmonth(index)) %&gt;%\n  as_tsibble(index = index)\n\nrec_tibble &lt;- tk_tbl(rec) %&gt;% rename(rec = value)\n\nrec_tsibble &lt;- rec_tibble %&gt;% mutate(index = yearmonth(index)) %&gt;%\n  as_tsibble(index = index)\n\nsoi_tsibble %&gt;% \n  ggplot(aes(x = index, y = soi)) +\n  geom_line() +\n  labs(x = \"Tiempo\", y = \"SOI\")+\n  theme_bw()\n\n\n\n\n\n\n\nrec_tsibble %&gt;% \n  ggplot(aes(x = index, y = rec)) +\n  geom_line() +\n  labs(x = \"Tiempo\", y = \"REC\")+\n  theme_bw()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Enfoque de Box-Jenkins</span>"
    ]
  },
  {
    "objectID": "box_jenk.html#gráficos-de-la-función-de-autocorrelación-estimada.",
    "href": "box_jenk.html#gráficos-de-la-función-de-autocorrelación-estimada.",
    "title": "1  Enfoque de Box-Jenkins",
    "section": "1.2 Gráficos de la función de autocorrelación estimada.",
    "text": "1.2 Gráficos de la función de autocorrelación estimada.\nSiguiendo este último ejemplo, vamos a calcular el ACF de ambas series de SOI y REC:\n\nACF_soi &lt;- soi_tsibble %&gt;% ACF(soi,lag_max = 24)\n\nsoi_tsibble %&gt;% ACF(soi,lag_max = 24) %&gt;%\n  autoplot() +\n  theme_bw()+labs(x = \"Lag\", y = \"ACF\")\n\n\n\n\n\n\n\nrec_tsibble %&gt;% ACF(rec,lag_max = 24) %&gt;%\n  autoplot() +\n  theme_bw()+labs(x = \"Lag\", y = \"ACF\")\n\n\n\n\n\n\n\n\nNoten que en la primera línea del codigo anterior se extrae directamente el ACF de la serie SOI. A continuación el CCF de ambas series:\n\nsoi_rec_tsibble &lt;- soi_tsibble %&gt;% left_join(rec_tsibble,by = \"index\")\n\nsoi_rec_tsibble %&gt;% CCF(x = soi, y = rec, lag_max = 24) %&gt;%\n  autoplot() +\n  theme_bw() +\n  labs(x = \"Lag\", y = \"CCF\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Enfoque de Box-Jenkins</span>"
    ]
  },
  {
    "objectID": "box_jenk.html#análisis-exploratorio-de-series-de-tiempo",
    "href": "box_jenk.html#análisis-exploratorio-de-series-de-tiempo",
    "title": "1  Enfoque de Box-Jenkins",
    "section": "1.3 Análisis exploratorio de series de tiempo",
    "text": "1.3 Análisis exploratorio de series de tiempo\n\n1.3.1 Descomposición de componente trigonométrico:\n\nset.seed(1492)\nnum &lt;- 120\nt &lt;- 1:num\n\nX &lt;- ts(2*cos(2*pi*t/12) + rnorm(120), frequency = 12)\nY &lt;- ts(2*cos(2*pi*(t+5)/12) + rnorm(120), frequency = 12)\n\n\nYw &lt;- resid(lm(Y ~ cos(2*pi*t/12) + sin(2*pi*t/12)))\n\n\nX_df &lt;- data.frame(\n  index = time(X),\n  value = as.numeric(X),\n  series = \"X\"\n)\n\nYw_df &lt;- data.frame(\n  index = time(Y),\n  value = as.numeric(Yw),\n  series = \"Yw\"\n)\n\n\ncombined_df &lt;- bind_rows(X_df, Yw_df)\n\n\ncombined_tsibble &lt;- as_tsibble(combined_df, index = index, key = series)\n\n\nggplot(combined_tsibble, aes(x = index, y = value)) +\n  geom_line() +\n  facet_wrap(~series, scales = \"free_y\") +  # Facet plot with free y-axis scales\n  labs(title = \"Time Series Plot\",\n       x = \"Time\",\n       y = \"Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nCon lo cual se compara una de las dos series originales con los residuos después de haberle ajustado un componente triginométrico.\n\n\n1.3.2 Descomposición de tendencia a través de regresión lineal\n\nchicken_tibble &lt;- tk_tbl(chicken)\n\nchicken_tsibble &lt;- as_tsibble(chicken, index = time(chicken)) %&gt;%\n  rename(chicken = value)\n\nfit_pollo &lt;- chicken_tsibble %&gt;%\n  model(lm = TSLM(chicken ~ trend()))\n\nmodel_summary &lt;- glance(fit_pollo)\nprint(model_summary)\n\n# A tibble: 1 × 15\n  .model r_squared adj_r_squared sigma2 statistic  p_value    df log_lik   AIC\n  &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 lm         0.917         0.917   22.1     1974. 2.83e-98     2   -533.  561.\n# ℹ 6 more variables: AICc &lt;dbl&gt;, BIC &lt;dbl&gt;, CV &lt;dbl&gt;, deviance &lt;dbl&gt;,\n#   df.residual &lt;int&gt;, rank &lt;int&gt;\n\nmodel_coefficients &lt;- tidy(fit_pollo)\nprint(model_coefficients)\n\n# A tibble: 2 × 6\n  .model term        estimate std.error statistic   p.value\n  &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 lm     (Intercept)   58.6     0.703        83.3 1.54e-144\n2 lm     trend()        0.299   0.00674      44.4 2.83e- 98\n\nresiduals_df &lt;- augment(fit_pollo) %&gt;%\n  select(index, .resid) %&gt;%\n  rename(residuals = .resid)\n\n\nggplot(residuals_df, aes(x = index, y = residuals)) +\n  geom_line() +\n  labs(title = \"Residuals of the Linear Model\",\n       x = \"Time\",\n       y = \"Residuals\") +\n  theme_minimal()\n\n\n\n\n\n\n\nacf_residuals &lt;- acf(residuals_df$residuals, plot = FALSE)\n\nacf_df &lt;- data.frame(\n  lag = acf_residuals$lag,\n  acf = acf_residuals$acf\n)\n\nggplot(acf_df, aes(x = lag, y = acf)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"ACF of Residuals\",\n       x = \"Lag\",\n       y = \"ACF\") +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Enfoque de Box-Jenkins</span>"
    ]
  },
  {
    "objectID": "cap4.html",
    "href": "cap4.html",
    "title": "2  Capítulo 4",
    "section": "",
    "text": "2.1 Decomposing a Non-Sinusoidal Cycle Using Regression",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap4.html#decomposing-a-non-sinusoidal-cycle-using-regression",
    "href": "cap4.html#decomposing-a-non-sinusoidal-cycle-using-regression",
    "title": "2  Capítulo 4",
    "section": "",
    "text": "2.1.1 Introduction\nThis example demonstrates how to decompose a simple dataset into its frequency components using regression. The data given complete one cycle but not in a sinusoidal way, so the first frequency component \\(\\omega_1 = 1/5\\) is expected to be large, while the second component \\(\\omega_2 = 2/5\\) is expected to be small.\n\n\n2.1.2 Data and Frequency Components\nThe dataset ( x = {1, 2, 3, 2, 1} ) is examined with the two frequency components. We use cosines and sines at the relevant frequencies to perform the decomposition.\n\n# Define the dataset\nx = c(1, 2, 3, 2, 1)\n\n# Define cosine and sine terms for the first and second frequency components\nc1 = cos(2 * pi * 1:5 * 1/5)\ns1 = sin(2 * pi * 1:5 * 1/5)\nc2 = cos(2 * pi * 1:5 * 2/5)\ns2 = sin(2 * pi * 1:5 * 2/5)\n\n# Combine the components into matrices for regression\nomega1 = cbind(c1, s1)\nomega2 = cbind(c2, s2)\nanova(lm(x~omega1+omega2))\n\nWarning in anova.lm(lm(x ~ omega1 + omega2)): ANOVA F-tests on an essentially\nperfect fit are unreliable\n\n\nAnalysis of Variance Table\n\nResponse: x\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\nomega1     2 2.74164 1.37082     NaN    NaN\nomega2     2 0.05836 0.02918     NaN    NaN\nResiduals  0 0.00000     NaN               \n\n\nThis analysis presents the periodograms of the SOI and Recruitment series. It explores the significance of certain periodicities, particularly the yearly cycle and a potential four-year El Niño cycle. Confidence intervals for these spectral peaks are also calculated, but the results show wide intervals, making it difficult to assert the significance of the four-year cycle. The periodograms for the SOI and Recruitment series show: - A narrow-band peak at the yearly cycle ( \\(\\omega = 1/12\\) ). - A wide-band peak centered around the four-year cycle ( \\(\\omega = 1/48\\) ), possibly linked to El Niño.\n\n### R Code to Reproduce the Periodogram\n# Load the astsa package\nlibrary(astsa)\n\n# Set up plotting parameters\npar(mfrow=c(2,1))\n\n# Compute and plot the periodogram for the SOI series\nsoi.per = mvspec(soi, log=\"no\")\nabline(v=1/4, lty=2) # Add a vertical line at the four-year cycle\n\n# Compute and plot the periodogram for the Recruitment series\nrec.per = mvspec(rec, log=\"no\")\nabline(v=1/4, lty=2)\n\n\n\n\n\n\n\n\nConfidence Intervals for Spectral Estimates\nWe compute approximate 95% confidence intervals for the spectrum at the yearly cycle \\(\\omega=1/12\\), and the possible four-year cycle \\(\\omega = 1/48\\).\n\n# Confidence interval boundaries\nU = qchisq(.025, 2)  # 0.05063\nL = qchisq(.975, 2)  # 7.37775\n\n# SOI periodogram values at specific frequencies\nsoi_per_1_12 = soi.per$spec[40] # SOI periodogram at freq 1/12 = 40/480\nsoi_per_1_48 = soi.per$spec[10] # SOI periodogram at freq 1/48 = 10/480\n\n# Confidence intervals for the yearly cycle\nCI_1_12 = c(2 * soi_per_1_12 / L, 2 * soi_per_1_12 / U) \nCI_1_12 # Approximate 95% CI for the yearly cycle\n\n[1]  0.2635573 38.4010800\n\n# Confidence intervals for the four-year cycle\nCI_1_48 = c(2 * soi_per_1_48 / L, 2 * soi_per_1_48 / U) \nCI_1_48 # Approximate 95% CI for the four-year cycle\n\n[1] 0.0145653 2.1222066\n\n\nInterpretation\n\nThe periodogram at the yearly cycle \\(\\omega = 1/12\\) is significant, with a 95% confidence interval that suggests its importance in the SOI series.\nThe wide confidence interval at \\(\\omega= 1/48\\) (representing the four-year cycle) indicates that this peak may not be significant.\n\nConclusion\nThe periodogram analysis suggests the presence of a strong yearly cycle and a possible but irregular four-year cycle, which could be linked to El Niño. Further analysis is required to refine these findings.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap4.html#smoothing-the-periodogram",
    "href": "cap4.html#smoothing-the-periodogram",
    "title": "2  Capítulo 4",
    "section": "2.2 Smoothing the Periodogram",
    "text": "2.2 Smoothing the Periodogram\nThis example shows the smoothed periodogram for the SOI and Recruitment series, using a Daniell kernel to average the periodograms computed earlier. The goal is to reduce noise in the spectrum while maintaining key features, particularly the El Niño frequency. The smoothed spectra help in identifying the predominant periods and their significance.\n\n2.2.1 Averaged Periodogram Calculation\nThe Daniell kernel is used with ( L = 9 ) to compute the averaged periodograms. This provides a balance between noise reduction and retaining important peaks, as shown in the R code below.\n\n# Compute and plot the averaged periodogram for SOI\nsoi.ave = mvspec(soi, kernel('daniell', 4), log='no')\n\nBandwidth: 0.225 \nDegrees of Freedom: 16.99 \n\nabline(v=c(.25, 1, 2, 3), lty=2) # Add vertical lines at key frequencies\n\n\n\n\n\n\n\n# Display bandwidth of the SOI periodogram\nsoi.ave$bandwidth\n\n[1] 0.225\n\n# Bandwidth is 0.225, adjusted for the frequency scale in cycles per year\n\n# Compute and plot the averaged periodogram for Recruitment series\nrec.ave = mvspec(rec, kernel('daniell', 4), log='no')\n\nBandwidth: 0.225 \nDegrees of Freedom: 16.99 \n\nabline(v=c(.25, 1, 2, 3), lty=2) # Add vertical lines at key frequencies\n\n\n\n\n\n\n\n\nConfidence Intervals for Spectral Peaks\nWe compute 95% confidence intervals for the SOI spectrum at key frequencies, such as the El Niño cycle (48 months) and the yearly cycle.\n\n# Degrees of freedom for the averaged periodogram\ndf = soi.ave$df\ndf # Returned value: 16.9875\n\n[1] 16.9875\n\n# Compute chi-squared limits\nU = qchisq(.025, df)  # Upper limit\nL = qchisq(.975, df)  # Lower limit\n\n# Spectrum values at key frequencies\nsoi_spec_1_48 = soi.ave$spec[10]  # Spectrum at frequency 1/48\nsoi_spec_1_12 = soi.ave$spec[40]  # Spectrum at frequency 1/12\n\n# Confidence intervals for the 48-month (El Niño) cycle\nCI_1_48 = c(df * soi_spec_1_48 / L, df * soi_spec_1_48 / U)\nCI_1_48 # Approximate 95% confidence interval for 1/48\n\n[1] 0.02787891 0.11133335\n\n# Confidence intervals for the yearly cycle (1/12)\nCI_1_12 = c(df * soi_spec_1_12 / L, df * soi_spec_1_12 / U)\nCI_1_12 # Approximate 95% confidence interval for 1/12\n\n[1] 0.06703963 0.26772011\n\n\nInterpretation\nThe smoothed spectra highlight the El Niño frequency and the yearly cycle more clearly:\n\nAt \\(\\omega=1/12\\) (yearly cycle), the smoothing slightly flattens and spreads the peak. Harmonics of the yearly cycle appear at frequencies like \\(\\omega=1\\Delta,2\\Delta,\\cdots\\).\nConfidence intervals suggest that the El Niño frequency (48 months) shows significant power, with lower limits exceeding baseline spectral levels, confirming its importance in the SOI and Recruitment series.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap4.html#introduction-1",
    "href": "cap4.html#introduction-1",
    "title": "2  Capítulo 4",
    "section": "2.3 Introduction",
    "text": "2.3 Introduction\nThis example shows how to estimate the spectra of the SOI and Recruitment series using a smoothed periodogram. A modified Daniell kernel with ( m = 3 ) is applied, and the periodogram is smoothed twice. The resulting estimates are considered more visually appealing than those in previous examples.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap4.html#smoothing-the-periodogram-with-a-modified-daniell-kernel",
    "href": "cap4.html#smoothing-the-periodogram-with-a-modified-daniell-kernel",
    "title": "2  Capítulo 4",
    "section": "2.4 Smoothing the Periodogram with a Modified Daniell Kernel",
    "text": "2.4 Smoothing the Periodogram with a Modified Daniell Kernel\nWe use the Daniell kernel, smoothed with ( m = 3 ), to estimate the spectra. The kernel coefficients are shown below.\n\n# Define and plot the modified Daniell kernel with m = 3\nk = kernel(\"modified.daniell\", c(3, 3))\n\n# Display the kernel coefficients\nk$coef\n\n[1] 0.152777778 0.138888889 0.111111111 0.083333333 0.055555556 0.027777778\n[7] 0.006944444\n\n# Plot the kernel\nplot(k)\n\n\n\n\n\n\n\n\nEstimating the Spectra for the SOI Series\nWe now apply the smoothed kernel to the SOI series, plot the periodogram, and calculate the bandwidth and degrees of freedom.\n\n# Calculate and plot the smoothed periodogram for the SOI series\nsoi.smo = mvspec(soi, kernel=k, taper=.1, log=\"no\")\n\nBandwidth: 0.231 \nDegrees of Freedom: 15.61 \n\nabline(v=c(.25, 1), lty=2) # Add vertical lines at key frequencies\n\n\n\n\n\n\n\n# Retrieve degrees of freedom and bandwidth\ndf_soi = soi.smo$df\nbandwidth_soi = soi.smo$bandwidth\n\nsoi.smo$spec[soi.smo$freq==1]\n\n[1] 0.1675368\n\ndf_soi*soi.smo$spec[soi.smo$freq==1]/qchisq(0.975,df = df_soi)\n\n[1] 0.09235481\n\ndf_soi*soi.smo$spec[soi.smo$freq==1]/qchisq(0.025,df = df_soi)\n\n[1] 0.3929982\n\n# Display degrees of freedom and bandwidth\ndf_soi  # Degrees of freedom: 17.42618\n\n[1] 15.61029\n\nbandwidth_soi  # Bandwidth: 0.2308103\n\n[1] 0.2308103\n\n\nEstimating the Spectra for the Recruitment Series\nWe repeat the above steps for the Recruitment series.\n\n# Calculate and plot the smoothed periodogram for the Recruitment series\nrec.smo = mvspec(rec, kernel=k, taper=.1, log=\"no\")\n\nBandwidth: 0.231 \nDegrees of Freedom: 15.61 \n\nabline(v=c(.25, 1), lty=2) # Add vertical lines at key frequencies\n\n\n\n\n\n\n\n# Retrieve degrees of freedom and bandwidth\ndf_rec = rec.smo$df\nbandwidth_rec = rec.smo$bandwidth\n\n# Display degrees of freedom and bandwidth\ndf_rec  # Degrees of freedom: same as SOI\n\n[1] 15.61029\n\nbandwidth_rec  # Bandwidth: same as SOI\n\n[1] 0.2308103",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap4.html#smoothed-periodogram-for-soi-and-recruitment-series",
    "href": "cap4.html#smoothed-periodogram-for-soi-and-recruitment-series",
    "title": "2  Capítulo 4",
    "section": "2.5 Smoothed Periodogram for SOI and Recruitment Series",
    "text": "2.5 Smoothed Periodogram for SOI and Recruitment Series\n\n2.5.1 Introduction\nThis example shows how to estimate the spectra of the SOI and Recruitment series using a smoothed periodogram with a modified Daniell kernel. The kernel is smoothed twice with ( m = 3 ), yielding ( \\(L = 2m + 1 = 7\\) ). The bandwidth and degrees of freedom are calculated, and a taper of 10% is applied to reduce leakage effects.\n\n\n2.5.2 Defining the Modified Daniell Kernel\nThe modified Daniell kernel is created and its coefficients are displayed. This kernel is used to smooth the periodogram.\n\n# Define and plot the modified Daniell kernel with m = 3\nk = kernel(\"modified.daniell\", c(3, 3))\n\n# Display the kernel coefficients\nk$coef\n\n[1] 0.152777778 0.138888889 0.111111111 0.083333333 0.055555556 0.027777778\n[7] 0.006944444\n\n# Plot the kernel\nplot(k)\n\n\n\n\n\n\n\n\n\n\n2.5.3 Smoothed Spectral Estimate for SOI\nThe smoothed periodogram for the SOI series is calculated, applying a 10% taper to reduce spectral leakage. The degrees of freedom and bandwidth are then retrieved.\n\n# Calculate and plot the smoothed periodogram for the SOI series\nsoi.smo = mvspec(soi, kernel=k, taper=.1, log=\"no\")\n\nBandwidth: 0.231 \nDegrees of Freedom: 15.61 \n\nabline(v=c(.25, 1), lty=2) # Add vertical lines at key frequencies\n\n\n\n\n\n\n\n# Retrieve degrees of freedom and bandwidth\ndf_soi = soi.smo$df\nbandwidth_soi = soi.smo$bandwidth\n\n# Display degrees of freedom and bandwidth\ndf_soi  # Degrees of freedom: 17.42618\n\n[1] 15.61029\n\nbandwidth_soi  # Bandwidth: 0.2308103\n\n[1] 0.2308103\n\n\n\n\n2.5.4 Smoothed Spectral Estimate for Recruitment\nWe repeat the steps for the Recruitment series.\n\n# Calculate and plot the smoothed periodogram for the Recruitment series\nrec.smo = mvspec(rec, kernel=k, taper=.1, log=\"no\")\n\nBandwidth: 0.231 \nDegrees of Freedom: 15.61 \n\nabline(v=c(.25, 1), lty=2) # Add vertical lines at key frequencies\n\n\n\n\n\n\n\n# Retrieve degrees of freedom and bandwidth\ndf_rec = rec.smo$df\nbandwidth_rec = rec.smo$bandwidth\n\n# Display degrees of freedom and bandwidth\ndf_rec  # Degrees of freedom: same as SOI\n\n[1] 15.61029\n\nbandwidth_rec  # Bandwidth: same as SOI\n\n[1] 0.2308103\n\n\n\n\n2.5.5 Alternative Method for Estimation\nAn alternative way to generate the smoothed periodogram is by using the spans argument instead of explicitly defining the Daniell kernel. The spans vector specifies the smoothing parameter in terms of \\(L=2m+1\\), where \\(m=3\\).\n\n# Alternative method using spans to define the smoothing parameter\nsoi.smo_alt = mvspec(soi, taper=.1, spans=c(7, 7))\n\nBandwidth: 0.231 \nDegrees of Freedom: 15.61",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap4.html#the-effect-of-tapering-on-the-soi-series",
    "href": "cap4.html#the-effect-of-tapering-on-the-soi-series",
    "title": "2  Capítulo 4",
    "section": "2.6 The Effect of Tapering on the SOI Series",
    "text": "2.6 The Effect of Tapering on the SOI Series\n\n2.6.1 Introduction\nIn this example, we examine how tapering affects the spectral estimate of the SOI series. Tapering helps mitigate the effect of spectral leakage, which can blur periodic signals in the data. We compare the spectrum with no tapering against a spectrum with full tapering (50%). The fully tapered spectrum better distinguishes between the yearly cycle ($= 1 \\() and the El Niño cycle (\\) = 1/4 $).\n\n\n2.6.2 Spectral Estimation with and without Tapering\nWe calculate the spectral estimate of the SOI series twice: once with no tapering and once with full tapering (50%).\n\n# Calculate the spectrum with no tapering\ns0 = mvspec(soi, spans=c(7, 7), plot=FALSE) # No taper\n\n# Calculate the spectrum with full tapering (50%)\ns50 = mvspec(soi, spans=c(7, 7), taper=.5, plot=FALSE) # Full taper\n\n\n\n2.6.3 Plotting the Spectral Estimates\nWe now plot the spectral estimates on a log scale, using a solid line for the fully tapered spectrum and a dashed line for the non-tapered spectrum.\n\n# Plot the fully tapered spectrum (solid line)\nplot(s50$freq, s50$spec, log=\"y\", type=\"l\", ylab=\"Spectrum\", xlab=\"Frequency\")\n\n# Add the non-tapered spectrum (dashed line)\nlines(s0$freq, s0$spec, lty=2) # Dashed line for no taper\n\n\n\n\n\n\n\n\n\n\n2.6.4 Interpretation\nFrom the plot, we observe that tapering (solid line) leads to better separation between the yearly cycle (\\(\\omega=1\\)) and the El Niño cycle (\\(\\omega=1/4\\)). The non-tapered spectrum (dashed line) shows more spectral leakage, blurring these two important periodic components. By applying a taper, we reduce this leakage and obtain a clearer picture of the underlying spectral features.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Capítulo 4</span>"
    ]
  },
  {
    "objectID": "cap5.html",
    "href": "cap5.html",
    "title": "3  Capítulo 5",
    "section": "",
    "text": "3.1 Analysis of U.S. GNP",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Capítulo 5</span>"
    ]
  },
  {
    "objectID": "cap5.html#analysis-of-u.s.-gnp",
    "href": "cap5.html#analysis-of-u.s.-gnp",
    "title": "3  Capítulo 5",
    "section": "",
    "text": "3.1.1 Background\nIn Example 3.39, we fit an MA(2) model and an AR(1) model to the U.S. GNP series. The residuals from both models appeared to resemble a white noise process, but Example 3.43 suggested that the AR(1) model might be a better fit. It has been proposed that the U.S. GNP series may exhibit ARCH (Autoregressive Conditional Heteroskedasticity) errors, so we will investigate this possibility in this example.\nIf the GNP noise term follows an ARCH process, the squared residuals from the model should behave like a non-Gaussian AR(1) process, as noted in Equation 5.39.\n\n3.1.1.1 Initial Analysis of Residuals\nThe following R code generates the ACF and PACF plots of the squared residuals to check for remaining dependence:\n\nlibrary(astsa)\n# Fit AR(1) model to differenced log-transformed GNP\nu &lt;- sarima(diff(log(gnp)), 1, 0, 0)\n\ninitial  value -4.589567 \niter   2 value -4.654150\niter   3 value -4.654150\niter   4 value -4.654151\niter   4 value -4.654151\niter   4 value -4.654151\nfinal  value -4.654151 \nconverged\ninitial  value -4.655919 \niter   2 value -4.655921\niter   3 value -4.655922\niter   4 value -4.655922\niter   5 value -4.655922\niter   5 value -4.655922\niter   5 value -4.655922\nfinal  value -4.655922 \nconverged\n&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n \nCoefficients: \n      Estimate     SE t.value p.value\nar1     0.3467 0.0627  5.5255       0\nxmean   0.0083 0.0010  8.5398       0\n\nsigma^2 estimated as 9.029569e-05 on 220 degrees of freedom \n \nAIC = -6.44694  AICc = -6.446693  BIC = -6.400958 \n \n\n\n\n\n\n\n\n\nacf2(resid(u$fit)^2, 20)  # ACF and PACF of squared residuals\n\n\n\n\n\n\n\n\n     [,1] [,2] [,3] [,4]  [,5] [,6]  [,7] [,8] [,9] [,10] [,11] [,12] [,13]\nACF  0.12 0.13 0.03 0.13  0.01 0.05 -0.03 0.06 0.08 -0.08  0.09  0.10  0.01\nPACF 0.12 0.12 0.00 0.12 -0.02 0.02 -0.04 0.05 0.08 -0.12  0.11  0.09 -0.05\n     [,14] [,15] [,16] [,17] [,18] [,19] [,20]\nACF   0.04  0.15 -0.02  0.04 -0.05  0.01  0.05\nPACF  0.05  0.13 -0.09  0.01 -0.05  0.00  0.04\n\n\nThe plots reveal that there may be some small remaining dependence in the squared residuals.\n\n\n3.1.1.2 Fitting an AR(1)-ARCH(1) Model\nTo examine the ARCH nature of the residuals, we fit an AR(1)-ARCH(1) model to the GNP returns using the fGarch package. The garchFit function models the AR(1) and ARCH(1) components. The code and a summary of the results are shown below:\n\nlibrary(fGarch)\n\nNOTE: Packages 'fBasics', 'timeDate', and 'timeSeries' are no longer\nattached to the search() path when 'fGarch' is attached.\n\nIf needed attach them yourself in your R script by e.g.,\n        require(\"timeSeries\")\n\n# Fit AR(1)-ARCH(1) model\nfit &lt;- garchFit(~ arma(1, 0) + garch(1, 0), data = diff(log(gnp)))\n\n\nSeries Initialization:\n ARMA Model:                arma\n Formula Mean:              ~ arma(1, 0)\n GARCH Model:               garch\n Formula Variance:          ~ garch(1, 0)\n ARMA Order:                1 0\n Max ARMA Order:            1\n GARCH Order:               1 0\n Max GARCH Order:           1\n Maximum Order:             1\n Conditional Dist:          norm\n h.start:                   2\n llh.start:                 1\n Length of Series:          222\n Recursion Init:            mci\n Series Scale:              0.01015924\n\nParameter Initialization:\n Initial Parameters:          $params\n Limits of Transformations:   $U, $V\n Which Parameters are Fixed?  $includes\n Parameter Matrix:\n                     U          V    params includes\n    mu     -8.20681904   8.206819 0.8205354     TRUE\n    ar1    -0.99999999   1.000000 0.3466459     TRUE\n    omega   0.00000100 100.000000 0.1000000     TRUE\n    alpha1  0.00000001   1.000000 0.1000000     TRUE\n    gamma1 -0.99999999   1.000000 0.1000000    FALSE\n    delta   0.00000000   2.000000 2.0000000    FALSE\n    skew    0.10000000  10.000000 1.0000000    FALSE\n    shape   1.00000000  10.000000 4.0000000    FALSE\n Index List of Parameters to be Optimized:\n    mu    ar1  omega alpha1 \n     1      2      3      4 \n Persistence:                  0.1 \n\n\n--- START OF TRACE ---\nSelected Algorithm: nlminb \n\nR coded nlminb Solver: \n\n  0:     682.89527: 0.820535 0.346646 0.100000 0.100000\n  1:     308.43148: 0.763492 0.258112  1.06104 0.352453\n  2:     306.07332: 0.681276 0.195897  1.04763 0.304072\n  3:     301.00807: 0.561958 0.448458 0.825277 0.0402737\n  4:     298.88361: 0.383716 0.465477 0.632947 0.385969\n  5:     296.74288: 0.504144 0.389445 0.683635 0.247795\n  6:     296.67703: 0.497724 0.366843 0.688130 0.229496\n  7:     296.60039: 0.500011 0.385702 0.703145 0.211105\n  8:     296.59692: 0.515646 0.374174 0.690079 0.194961\n  9:     296.56381: 0.513570 0.367018 0.702272 0.200013\n 10:     296.55723: 0.523440 0.363126 0.708406 0.194151\n 11:     296.55632: 0.522578 0.364913 0.710104 0.194839\n 12:     296.55598: 0.520871 0.364956 0.710924 0.193212\n 13:     296.55568: 0.519486 0.366571 0.710212 0.194511\n 14:     296.55568: 0.519509 0.366597 0.710266 0.194512\n 15:     296.55568: 0.519511 0.366585 0.710290 0.194451\n 16:     296.55568: 0.519505 0.366562 0.710299 0.194464\n 17:     296.55568: 0.519526 0.366560 0.710295 0.194472\n 18:     296.55568: 0.519522 0.366563 0.710295 0.194471\n\nFinal Estimate of the Negative LLH:\n LLH:  -722.2849    norm LLH:  -3.253536 \n          mu          ar1        omega       alpha1 \n0.0052779470 0.3665625656 0.0000733096 0.1944713341 \n\nR-optimhess Difference Approximated Hessian Matrix:\n                 mu           ar1         omega        alpha1\nmu     -2749495.418 -24170.124984  4.546826e+06 -1.586692e+03\nar1      -24170.125   -390.266822  1.253879e+04 -6.733789e+00\nomega   4546825.784  12538.791045 -1.590043e+10 -7.069342e+05\nalpha1    -1586.692     -6.733789 -7.069342e+05 -1.425395e+02\nattr(,\"time\")\nTime difference of 0.004873753 secs\n\n--- END OF TRACE ---\n\n\nTime to Estimate Parameters:\n Time difference of 0.04393435 secs\n\nsummary(fit)\n\n\nTitle:\n GARCH Modelling \n\nCall:\n garchFit(formula = ~arma(1, 0) + garch(1, 0), data = diff(log(gnp))) \n\nMean and Variance Equation:\n data ~ arma(1, 0) + garch(1, 0)\n&lt;environment: 0x55f169b16e90&gt;\n [data = diff(log(gnp))]\n\nConditional Distribution:\n norm \n\nCoefficient(s):\n        mu         ar1       omega      alpha1  \n0.00527795  0.36656257  0.00007331  0.19447133  \n\nStd. Errors:\n based on Hessian \n\nError Analysis:\n        Estimate  Std. Error  t value Pr(&gt;|t|)    \nmu     5.278e-03   8.996e-04    5.867 4.44e-09 ***\nar1    3.666e-01   7.514e-02    4.878 1.07e-06 ***\nomega  7.331e-05   9.011e-06    8.135 4.44e-16 ***\nalpha1 1.945e-01   9.554e-02    2.035   0.0418 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLog Likelihood:\n 722.2849    normalized:  3.253536 \n\nDescription:\n Mon Nov 18 16:04:59 2024 by user:  \n\n\nStandardised Residuals Tests:\n                                 Statistic     p-Value\n Jarque-Bera Test   R    Chi^2   9.1180362 0.010472337\n Shapiro-Wilk Test  R    W       0.9842406 0.014336495\n Ljung-Box Test     R    Q(10)   9.8743260 0.451587525\n Ljung-Box Test     R    Q(15)  17.5585456 0.286584404\n Ljung-Box Test     R    Q(20)  23.4136291 0.268943681\n Ljung-Box Test     R^2  Q(10)  19.2821015 0.036822455\n Ljung-Box Test     R^2  Q(15)  33.2364834 0.004352735\n Ljung-Box Test     R^2  Q(20)  37.7425917 0.009518989\n LM Arch Test       R    TR^2   25.4162474 0.012969006\n\nInformation Criterion Statistics:\n      AIC       BIC       SIC      HQIC \n-6.471035 -6.409726 -6.471669 -6.446282 \n\n\nThe estimates for the AR(1) component are ( = 0.005 ) (mu) and ( = 0.367 ) (ar1). The ARCH(1) parameters are ( _0 = 0 ) (omega) and ( _1 = 0.194 ), which is significant with a p-value around 0.02.\n\n\n3.1.1.3 Residual Diagnostics\nVarious tests were performed on the residuals and squared residuals. Notable results include:\n\nJarque-Bera Test: Chi-squared statistic of 9.118 (p-value = 0.010), suggesting some non-normal skewness and kurtosis in the residuals.\nShapiro-Wilk Test: W statistic of 0.984 (p-value = 0.014), indicating deviation from normality based on empirical order statistics.\nLjung-Box Tests:\n\nResiduals [R]: Q(20) statistic of 23.414 (p-value = 0.269), suggesting no significant autocorrelation in residuals.\nSquared Residuals [R^2]: Q(20) statistic of 37.743 (p-value = 0.010), indicating some dependence in squared residuals.\n\n\nThe diagnostics imply that the ARCH(1) model captures the non-constant variance pattern, with significant ARCH effects in the U.S. GNP series.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Capítulo 5</span>"
    ]
  },
  {
    "objectID": "cap5.html#arch-analysis-of-the-djia-returns",
    "href": "cap5.html#arch-analysis-of-the-djia-returns",
    "title": "3  Capítulo 5",
    "section": "3.2 ARCH Analysis of the DJIA Returns",
    "text": "3.2 ARCH Analysis of the DJIA Returns\n\n3.2.1 Background\nThe daily returns of the Dow Jones Industrial Average (DJIA) exhibit classic GARCH characteristics, including volatility clustering. Additionally, there is a low level of autocorrelation in the series itself. To capture both of these features, we fit an AR(1)-GARCH(1, 1) model to the series, assuming t-distributed errors for robustness in handling heavy tails.\n\n3.2.1.1 Data Preparation and Initial Analysis\nThe DJIA returns are computed as the daily log differences of closing prices. The ACF of the returns and squared returns reveal some autocorrelation in the returns and significant autocorrelation in the squared returns, suggesting the presence of GARCH effects. The initial analysis and autocorrelation functions can be plotted with:\n\nlibrary(xts)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nlibrary(astsa)\n# Calculate daily returns\ndjiar &lt;- diff(log(djia$Close))[-1]\n\n# Autocorrelation analysis\nacf2(djiar)     # Shows slight autocorrelation in returns\n\n\n\n\n\n\n\n\n     [,1]  [,2] [,3]  [,4]  [,5] [,6]  [,7] [,8]  [,9] [,10] [,11] [,12] [,13]\nACF  -0.1 -0.06 0.05 -0.02 -0.06 0.01 -0.02 0.02 -0.01  0.04 -0.01  0.04  0.01\nPACF -0.1 -0.07 0.04 -0.02 -0.06 0.00 -0.02 0.03 -0.01  0.04 -0.01  0.04  0.02\n     [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\nACF  -0.04 -0.06  0.06  0.00 -0.07  0.02  0.05 -0.06  0.04  0.01 -0.01     0\nPACF -0.04 -0.06  0.04  0.02 -0.06  0.00  0.04 -0.04  0.03  0.00  0.00     0\n     [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37]\nACF      0  0.03 -0.03  0.01  0.02 -0.02  0.01  0.01 -0.09  0.03  0.03 -0.02\nPACF     0  0.04 -0.03  0.00  0.02  0.00  0.00  0.01 -0.07  0.01  0.02  0.01\n     [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49]\nACF      0  0.03  0.02  0.01  0.00 -0.06     0     0 -0.01  0.02  0.00 -0.04\nPACF     0  0.01  0.04  0.02  0.01 -0.06     0     0 -0.01  0.01 -0.01 -0.05\n     [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61]\nACF  -0.04 -0.02  0.03  0.00  0.00  0.01 -0.03  0.02  0.02 -0.07  0.02  0.02\nPACF -0.04 -0.03  0.01  0.01  0.02  0.01 -0.03  0.01  0.02 -0.05  0.01  0.02\n\nacf2(djiar^2)   # Shows strong autocorrelation in squared returns\n\n\n\n\n\n\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\nACF   0.2 0.41 0.19 0.31 0.34 0.31 0.32 0.22 0.32  0.24  0.43  0.28  0.25  0.13\nPACF  0.2 0.39 0.08 0.15 0.25 0.13 0.11 0.01 0.11  0.05  0.23  0.08 -0.07 -0.16\n     [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\nACF   0.22  0.26  0.27  0.27  0.17  0.23  0.25  0.19  0.29  0.15  0.18  0.15\nPACF -0.03  0.04  0.03  0.05 -0.01  0.00  0.09 -0.09  0.07 -0.01  0.00  0.00\n     [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\nACF   0.28  0.22  0.22  0.14  0.16  0.20  0.14  0.25  0.10  0.17  0.12  0.16\nPACF  0.12  0.02 -0.03 -0.06  0.00  0.01 -0.06  0.06 -0.03 -0.05  0.02 -0.06\n     [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\nACF   0.15  0.10  0.08  0.08  0.11  0.13  0.13  0.08  0.09  0.11  0.07  0.08\nPACF -0.06 -0.06 -0.03  0.01  0.00  0.03  0.02 -0.01  0.00  0.06 -0.02 -0.05\n     [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61]\nACF   0.07  0.08  0.06  0.09  0.06  0.12  0.09  0.06  0.08  0.04  0.08\nPACF  0.03  0.04  0.02 -0.02 -0.09  0.08  0.06  0.00  0.01 -0.02  0.00\n\n\n\n\n3.2.1.2 Fitting an AR(1)-GARCH(1,1) Model\nThe fGarch package in R allows for fitting an AR(1)-GARCH(1, 1) model with t-distributed errors to account for potential heavy tails in the DJIA returns. The following code fits the model and provides a summary of the estimates:\n\nlibrary(fGarch)\n# Fit AR(1)-GARCH(1,1) model with t-distributed errors\ndjia.g &lt;- garchFit(~ arma(1, 0) + garch(1, 1), data = djiar, cond.dist = \"std\")\n\n\nSeries Initialization:\n ARMA Model:                arma\n Formula Mean:              ~ arma(1, 0)\n GARCH Model:               garch\n Formula Variance:          ~ garch(1, 1)\n ARMA Order:                1 0\n Max ARMA Order:            1\n GARCH Order:               1 1\n Max GARCH Order:           1\n Maximum Order:             1\n Conditional Dist:          std\n h.start:                   2\n llh.start:                 1\n Length of Series:          2517\n Recursion Init:            mci\n Series Scale:              0.01210097\n\nParameter Initialization:\n Initial Parameters:          $params\n Limits of Transformations:   $U, $V\n Which Parameters are Fixed?  $includes\n Parameter Matrix:\n                     U           V      params includes\n    mu     -0.15336279   0.1533628  0.01533395     TRUE\n    ar1    -0.99999999   1.0000000 -0.10129752     TRUE\n    omega   0.00000100 100.0000000  0.10000000     TRUE\n    alpha1  0.00000001   1.0000000  0.10000000     TRUE\n    gamma1 -0.99999999   1.0000000  0.10000000    FALSE\n    beta1   0.00000001   1.0000000  0.80000000     TRUE\n    delta   0.00000000   2.0000000  2.00000000    FALSE\n    skew    0.10000000  10.0000000  1.00000000    FALSE\n    shape   1.00000000  10.0000000  4.00000000     TRUE\n Index List of Parameters to be Optimized:\n    mu    ar1  omega alpha1  beta1  shape \n     1      2      3      4      6      9 \n Persistence:                  0.9 \n\n\n--- START OF TRACE ---\nSelected Algorithm: nlminb \n\nR coded nlminb Solver: \n\n  0:     2966.5649: 0.0153339 -0.101298 0.100000 0.100000 0.800000  4.00000\n  1:     2944.7772: 0.0153351 -0.0991717 0.0803850 0.105688 0.794226  3.99986\n  2:     2910.9438: 0.0153425 -0.0864389 0.0198837 0.162520 0.809278  4.00053\n  3:     2891.9985: 0.0153434 -0.0855696 0.0349997 0.168391 0.817707  4.00077\n  4:     2882.6364: 0.0153798 -0.0489475 0.0211398 0.164588 0.840541  4.00286\n  5:     2881.9301: 0.0153823 -0.0484838 0.0204238 0.166791 0.845394  4.00314\n  6:     2881.5679: 0.0153882 -0.0491671 0.0164038 0.164251 0.847793  4.00365\n  7:     2880.9558: 0.0153959 -0.0493820 0.0174436 0.161528 0.852261  4.00434\n  8:     2880.6291: 0.0154049 -0.0492037 0.0154767 0.158055 0.855764  4.00516\n  9:     2880.3565: 0.0154166 -0.0487266 0.0159444 0.154678 0.859712  4.00626\n 10:     2880.1243: 0.0154339 -0.0478609 0.0146355 0.150737 0.862389  4.00794\n 11:     2879.9530: 0.0154638 -0.0476576 0.0149075 0.147959 0.865388  4.01087\n 12:     2879.8201: 0.0155048 -0.0483157 0.0138749 0.146453 0.866639  4.01497\n 13:     2879.7180: 0.0155488 -0.0477882 0.0141937 0.145774 0.867564  4.01936\n 14:     2879.4141: 0.0157808 -0.0423403 0.0141381 0.141896 0.868277  4.04243\n 15:     2878.3878: 0.0174980 -0.0569546 0.00848860 0.140360 0.874674  4.21079\n 16:     2878.2927: 0.0193492 -0.0502757 0.0142265 0.160178 0.862535  4.37200\n 17:     2876.3368: 0.0203874 -0.0461078 0.0117835 0.167862 0.852926  4.44641\n 18:     2874.7342: 0.0206459 -0.0555791 0.0130825 0.138689 0.869340  4.42804\n 19:     2874.6724: 0.0206462 -0.0554532 0.0123098 0.138461 0.869109  4.42806\n 20:     2874.6548: 0.0206553 -0.0553211 0.0125311 0.138489 0.869292  4.42857\n 21:     2874.6394: 0.0206635 -0.0550129 0.0122399 0.138334 0.869389  4.42904\n 22:     2874.6234: 0.0206727 -0.0548830 0.0124501 0.138349 0.869554  4.42956\n 23:     2874.6091: 0.0206813 -0.0546059 0.0121936 0.138189 0.869619  4.43005\n 24:     2874.5943: 0.0206905 -0.0544775 0.0123915 0.138195 0.869769  4.43057\n 25:     2874.5807: 0.0206992 -0.0542217 0.0121569 0.138035 0.869816  4.43107\n 26:     2874.5667: 0.0207085 -0.0540958 0.0123467 0.138034 0.869956  4.43160\n 27:     2874.5537: 0.0207174 -0.0538569 0.0121278 0.137877 0.869991  4.43211\n 28:     2874.5403: 0.0207267 -0.0537340 0.0123108 0.137872 0.870123  4.43264\n 29:     2874.5278: 0.0207356 -0.0535096 0.0121041 0.137717 0.870149  4.43315\n 30:     2874.5149: 0.0207450 -0.0533899 0.0122810 0.137709 0.870275  4.43368\n 31:     2874.5028: 0.0207540 -0.0531784 0.0120844 0.137558 0.870296  4.43419\n 32:     2874.4904: 0.0207635 -0.0530620 0.0122555 0.137548 0.870416  4.43473\n 33:     2874.4787: 0.0207726 -0.0528620 0.0120673 0.137401 0.870433  4.43525\n 34:     2874.4667: 0.0207820 -0.0527489 0.0122328 0.137390 0.870549  4.43578\n 35:     2874.4553: 0.0207912 -0.0525594 0.0120521 0.137247 0.870562  4.43630\n 36:     2874.4437: 0.0208007 -0.0524496 0.0122124 0.137235 0.870674  4.43684\n 37:     2874.4326: 0.0208099 -0.0522698 0.0120383 0.137096 0.870686  4.43736\n 38:     2874.4213: 0.0208194 -0.0521631 0.0121935 0.137083 0.870794  4.43789\n 39:     2874.4105: 0.0208287 -0.0519922 0.0120255 0.136949 0.870804  4.43842\n 40:     2874.3995: 0.0208383 -0.0518887 0.0121759 0.136934 0.870909  4.43895\n 41:     2874.3889: 0.0208476 -0.0517261 0.0120134 0.136805 0.870917  4.43948\n 42:     2874.3782: 0.0208572 -0.0516257 0.0121593 0.136790 0.871020  4.44002\n 43:     2874.3679: 0.0208666 -0.0514707 0.0120019 0.136664 0.871027  4.44055\n 44:     2874.3574: 0.0208762 -0.0513733 0.0121435 0.136649 0.871126  4.44108\n 45:     2874.3474: 0.0208856 -0.0512255 0.0119909 0.136527 0.871132  4.44161\n 46:     2874.3371: 0.0208952 -0.0511310 0.0121283 0.136511 0.871229  4.44215\n 47:     2874.3273: 0.0209047 -0.0509898 0.0119802 0.136393 0.871235  4.44268\n 48:     2874.3172: 0.0209144 -0.0508982 0.0121136 0.136378 0.871329  4.44321\n 49:     2874.3076: 0.0209239 -0.0507633 0.0119698 0.136263 0.871333  4.44374\n 50:     2874.2977: 0.0209336 -0.0506745 0.0120995 0.136247 0.871425  4.44428\n 51:     2874.2883: 0.0209431 -0.0505454 0.0119597 0.136136 0.871429  4.44481\n 52:     2874.2786: 0.0209528 -0.0504593 0.0120858 0.136120 0.871519  4.44535\n 53:     2874.2693: 0.0209624 -0.0503357 0.0119499 0.136012 0.871522  4.44588\n 54:     2874.2598: 0.0209721 -0.0502524 0.0120725 0.135996 0.871609  4.44641\n 55:     2874.2507: 0.0209817 -0.0501339 0.0119403 0.135891 0.871612  4.44694\n 56:     2874.2414: 0.0209915 -0.0500532 0.0120596 0.135875 0.871697  4.44748\n 57:     2874.2324: 0.0210011 -0.0499396 0.0119308 0.135773 0.871700  4.44801\n 58:     2867.2502: 0.0374784 -0.0465701 0.0140411 0.146417 0.849465  5.34102\n 59:     2865.2784: 0.0416151 -0.0568642 0.0115908 0.133741 0.863377  5.47854\n 60:     2864.2803: 0.0508382 -0.0551564 0.0133502 0.137240 0.863921  5.39588\n 61:     2861.7759: 0.0711833 -0.0514599 0.0116358 0.126101 0.868871  5.59207\n 62:     2861.6890: 0.0720867 -0.0568481 0.0103059 0.127155 0.870034  5.77185\n 63:     2861.6323: 0.0712594 -0.0580540 0.0105727 0.123206 0.871658  5.89046\n 64:     2861.6059: 0.0710100 -0.0558795 0.0112294 0.125022 0.869481  5.92682\n 65:     2861.6004: 0.0709184 -0.0550834 0.0110167 0.124375 0.870072  5.96212\n 66:     2861.6000: 0.0709561 -0.0553609 0.0109915 0.124443 0.870018  5.97670\n 67:     2861.6000: 0.0709474 -0.0553160 0.0109949 0.124443 0.870016  5.97866\n 68:     2861.6000: 0.0709478 -0.0553153 0.0109957 0.124445 0.870013  5.97877\n\nFinal Estimate of the Negative LLH:\n LLH:  -8249.619    norm LLH:  -3.27756 \n           mu           ar1         omega        alpha1         beta1 \n 8.585376e-04 -5.531526e-02  1.610146e-06  1.244449e-01  8.700127e-01 \n        shape \n 5.978770e+00 \n\nR-optimhess Difference Approximated Hessian Matrix:\n                  mu           ar1         omega        alpha1         beta1\nmu     -4.791651e+07 -4.661861e+04 -1.205634e+09 -3.466862e+04 -9.149105e+04\nar1    -4.661861e+04 -2.490882e+03 -1.234074e+06 -8.203053e+00 -9.744031e+01\nomega  -1.205634e+09 -1.234074e+06 -1.703962e+13 -5.515881e+08 -8.452220e+08\nalpha1 -3.466862e+04 -8.203053e+00 -5.515881e+08 -3.611224e+04 -4.469020e+04\nbeta1  -9.149105e+04 -9.744031e+01 -8.452220e+08 -4.469020e+04 -6.270062e+04\nshape  -9.970351e+02  8.557532e-02 -3.050363e+06 -1.832755e+02 -2.340762e+02\n               shape\nmu     -9.970351e+02\nar1     8.557532e-02\nomega  -3.050363e+06\nalpha1 -1.832755e+02\nbeta1  -2.340762e+02\nshape  -2.547431e+00\nattr(,\"time\")\nTime difference of 0.0685904 secs\n\n--- END OF TRACE ---\n\n\nTime to Estimate Parameters:\n Time difference of 0.3414211 secs\n\nsummary(djia.g)\n\n\nTitle:\n GARCH Modelling \n\nCall:\n garchFit(formula = ~arma(1, 0) + garch(1, 1), data = djiar, cond.dist = \"std\") \n\nMean and Variance Equation:\n data ~ arma(1, 0) + garch(1, 1)\n&lt;environment: 0x55f168599750&gt;\n [data = djiar]\n\nConditional Distribution:\n std \n\nCoefficient(s):\n         mu          ar1        omega       alpha1        beta1        shape  \n 8.5854e-04  -5.5315e-02   1.6101e-06   1.2444e-01   8.7001e-01   5.9788e+00  \n\nStd. Errors:\n based on Hessian \n\nError Analysis:\n         Estimate  Std. Error  t value Pr(&gt;|t|)    \nmu      8.585e-04   1.470e-04    5.842 5.16e-09 ***\nar1    -5.532e-02   2.023e-02   -2.735 0.006238 ** \nomega   1.610e-06   4.459e-07    3.611 0.000305 ***\nalpha1  1.244e-01   1.660e-02    7.496 6.55e-14 ***\nbeta1   8.700e-01   1.526e-02   57.022  &lt; 2e-16 ***\nshape   5.979e+00   7.917e-01    7.552 4.31e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLog Likelihood:\n 8249.619    normalized:  3.27756 \n\nDescription:\n Mon Nov 18 16:05:00 2024 by user:  \n\n\nStandardised Residuals Tests:\n                                  Statistic    p-Value\n Jarque-Bera Test   R    Chi^2  310.0081692 0.00000000\n Shapiro-Wilk Test  R    W        0.9820293 0.00000000\n Ljung-Box Test     R    Q(10)   16.8224601 0.07838596\n Ljung-Box Test     R    Q(15)   26.4481303 0.03356806\n Ljung-Box Test     R    Q(20)   28.7109935 0.09360790\n Ljung-Box Test     R^2  Q(10)   15.3676143 0.11922299\n Ljung-Box Test     R^2  Q(15)   19.1365044 0.20761469\n Ljung-Box Test     R^2  Q(20)   22.9288237 0.29230296\n LM Arch Test       R    TR^2    15.0397685 0.23926882\n\nInformation Criterion Statistics:\n      AIC       BIC       SIC      HQIC \n-6.550353 -6.536453 -6.550364 -6.545309 \n\n#plot(djia.g)  # View model diagnostic plots\n\n\n\n3.2.1.3 Summary of Results\nThe AR(1) coefficient ((_1)) is -0.05531, indicating a slight negative autocorrelation in returns. The GARCH parameters (_1 = 0.1244) and (_1 = 0.8700) are both significant, suggesting the model captures the observed volatility clustering in DJIA returns effectively.\n\n\n3.2.1.4 Residual Diagnostics\nResidual diagnostics are as follows:\n\nLjung-Box Test:\n\nResiduals ([R]): (Q(10) = 16.82) (p-value = 0.0786), suggesting no significant autocorrelation in residuals.\nSquared Residuals ([R^2]): (Q(10) = 15.39) (p-value = 0.1184), indicating no remaining ARCH effects.\n\n\nThese tests confirm that the AR(1)-GARCH(1, 1) model adequately captures the conditional heteroskedasticity in the DJIA returns.\n\n\n3.2.1.5 GARCH Predictions of Volatility\nWe explored GARCH predictions of volatility, particularly around the financial crisis of 2008. One-step-ahead predictions of volatility ((^2)) were plotted along with the observed data, as shown in Figure 5.6. This provides insight into how volatility predictions varied during a period of high market uncertainty.\n\n# Assuming `djia` is already loaded with a 'Close' column for DJIA closing prices\n# Calculate daily returns of DJIA\ndjiar &lt;- diff(log(djia$Close))[-1]\n\n# Fit the AR(1)-GARCH(1,1) model with t-distributed errors\ndjia.g &lt;- garchFit(~ arma(1, 0) + garch(1, 1), data = djiar, cond.dist = \"std\")\n\n\nSeries Initialization:\n ARMA Model:                arma\n Formula Mean:              ~ arma(1, 0)\n GARCH Model:               garch\n Formula Variance:          ~ garch(1, 1)\n ARMA Order:                1 0\n Max ARMA Order:            1\n GARCH Order:               1 1\n Max GARCH Order:           1\n Maximum Order:             1\n Conditional Dist:          std\n h.start:                   2\n llh.start:                 1\n Length of Series:          2517\n Recursion Init:            mci\n Series Scale:              0.01210097\n\nParameter Initialization:\n Initial Parameters:          $params\n Limits of Transformations:   $U, $V\n Which Parameters are Fixed?  $includes\n Parameter Matrix:\n                     U           V      params includes\n    mu     -0.15336279   0.1533628  0.01533395     TRUE\n    ar1    -0.99999999   1.0000000 -0.10129752     TRUE\n    omega   0.00000100 100.0000000  0.10000000     TRUE\n    alpha1  0.00000001   1.0000000  0.10000000     TRUE\n    gamma1 -0.99999999   1.0000000  0.10000000    FALSE\n    beta1   0.00000001   1.0000000  0.80000000     TRUE\n    delta   0.00000000   2.0000000  2.00000000    FALSE\n    skew    0.10000000  10.0000000  1.00000000    FALSE\n    shape   1.00000000  10.0000000  4.00000000     TRUE\n Index List of Parameters to be Optimized:\n    mu    ar1  omega alpha1  beta1  shape \n     1      2      3      4      6      9 \n Persistence:                  0.9 \n\n\n--- START OF TRACE ---\nSelected Algorithm: nlminb \n\nR coded nlminb Solver: \n\n  0:     2966.5649: 0.0153339 -0.101298 0.100000 0.100000 0.800000  4.00000\n  1:     2944.7772: 0.0153351 -0.0991717 0.0803850 0.105688 0.794226  3.99986\n  2:     2910.9438: 0.0153425 -0.0864389 0.0198837 0.162520 0.809278  4.00053\n  3:     2891.9985: 0.0153434 -0.0855696 0.0349997 0.168391 0.817707  4.00077\n  4:     2882.6364: 0.0153798 -0.0489475 0.0211398 0.164588 0.840541  4.00286\n  5:     2881.9301: 0.0153823 -0.0484838 0.0204238 0.166791 0.845394  4.00314\n  6:     2881.5679: 0.0153882 -0.0491671 0.0164038 0.164251 0.847793  4.00365\n  7:     2880.9558: 0.0153959 -0.0493820 0.0174436 0.161528 0.852261  4.00434\n  8:     2880.6291: 0.0154049 -0.0492037 0.0154767 0.158055 0.855764  4.00516\n  9:     2880.3565: 0.0154166 -0.0487266 0.0159444 0.154678 0.859712  4.00626\n 10:     2880.1243: 0.0154339 -0.0478609 0.0146355 0.150737 0.862389  4.00794\n 11:     2879.9530: 0.0154638 -0.0476576 0.0149075 0.147959 0.865388  4.01087\n 12:     2879.8201: 0.0155048 -0.0483157 0.0138749 0.146453 0.866639  4.01497\n 13:     2879.7180: 0.0155488 -0.0477882 0.0141937 0.145774 0.867564  4.01936\n 14:     2879.4141: 0.0157808 -0.0423403 0.0141381 0.141896 0.868277  4.04243\n 15:     2878.3878: 0.0174980 -0.0569546 0.00848860 0.140360 0.874674  4.21079\n 16:     2878.2927: 0.0193492 -0.0502757 0.0142265 0.160178 0.862535  4.37200\n 17:     2876.3368: 0.0203874 -0.0461078 0.0117835 0.167862 0.852926  4.44641\n 18:     2874.7342: 0.0206459 -0.0555791 0.0130825 0.138689 0.869340  4.42804\n 19:     2874.6724: 0.0206462 -0.0554532 0.0123098 0.138461 0.869109  4.42806\n 20:     2874.6548: 0.0206553 -0.0553211 0.0125311 0.138489 0.869292  4.42857\n 21:     2874.6394: 0.0206635 -0.0550129 0.0122399 0.138334 0.869389  4.42904\n 22:     2874.6234: 0.0206727 -0.0548830 0.0124501 0.138349 0.869554  4.42956\n 23:     2874.6091: 0.0206813 -0.0546059 0.0121936 0.138189 0.869619  4.43005\n 24:     2874.5943: 0.0206905 -0.0544775 0.0123915 0.138195 0.869769  4.43057\n 25:     2874.5807: 0.0206992 -0.0542217 0.0121569 0.138035 0.869816  4.43107\n 26:     2874.5667: 0.0207085 -0.0540958 0.0123467 0.138034 0.869956  4.43160\n 27:     2874.5537: 0.0207174 -0.0538569 0.0121278 0.137877 0.869991  4.43211\n 28:     2874.5403: 0.0207267 -0.0537340 0.0123108 0.137872 0.870123  4.43264\n 29:     2874.5278: 0.0207356 -0.0535096 0.0121041 0.137717 0.870149  4.43315\n 30:     2874.5149: 0.0207450 -0.0533899 0.0122810 0.137709 0.870275  4.43368\n 31:     2874.5028: 0.0207540 -0.0531784 0.0120844 0.137558 0.870296  4.43419\n 32:     2874.4904: 0.0207635 -0.0530620 0.0122555 0.137548 0.870416  4.43473\n 33:     2874.4787: 0.0207726 -0.0528620 0.0120673 0.137401 0.870433  4.43525\n 34:     2874.4667: 0.0207820 -0.0527489 0.0122328 0.137390 0.870549  4.43578\n 35:     2874.4553: 0.0207912 -0.0525594 0.0120521 0.137247 0.870562  4.43630\n 36:     2874.4437: 0.0208007 -0.0524496 0.0122124 0.137235 0.870674  4.43684\n 37:     2874.4326: 0.0208099 -0.0522698 0.0120383 0.137096 0.870686  4.43736\n 38:     2874.4213: 0.0208194 -0.0521631 0.0121935 0.137083 0.870794  4.43789\n 39:     2874.4105: 0.0208287 -0.0519922 0.0120255 0.136949 0.870804  4.43842\n 40:     2874.3995: 0.0208383 -0.0518887 0.0121759 0.136934 0.870909  4.43895\n 41:     2874.3889: 0.0208476 -0.0517261 0.0120134 0.136805 0.870917  4.43948\n 42:     2874.3782: 0.0208572 -0.0516257 0.0121593 0.136790 0.871020  4.44002\n 43:     2874.3679: 0.0208666 -0.0514707 0.0120019 0.136664 0.871027  4.44055\n 44:     2874.3574: 0.0208762 -0.0513733 0.0121435 0.136649 0.871126  4.44108\n 45:     2874.3474: 0.0208856 -0.0512255 0.0119909 0.136527 0.871132  4.44161\n 46:     2874.3371: 0.0208952 -0.0511310 0.0121283 0.136511 0.871229  4.44215\n 47:     2874.3273: 0.0209047 -0.0509898 0.0119802 0.136393 0.871235  4.44268\n 48:     2874.3172: 0.0209144 -0.0508982 0.0121136 0.136378 0.871329  4.44321\n 49:     2874.3076: 0.0209239 -0.0507633 0.0119698 0.136263 0.871333  4.44374\n 50:     2874.2977: 0.0209336 -0.0506745 0.0120995 0.136247 0.871425  4.44428\n 51:     2874.2883: 0.0209431 -0.0505454 0.0119597 0.136136 0.871429  4.44481\n 52:     2874.2786: 0.0209528 -0.0504593 0.0120858 0.136120 0.871519  4.44535\n 53:     2874.2693: 0.0209624 -0.0503357 0.0119499 0.136012 0.871522  4.44588\n 54:     2874.2598: 0.0209721 -0.0502524 0.0120725 0.135996 0.871609  4.44641\n 55:     2874.2507: 0.0209817 -0.0501339 0.0119403 0.135891 0.871612  4.44694\n 56:     2874.2414: 0.0209915 -0.0500532 0.0120596 0.135875 0.871697  4.44748\n 57:     2874.2324: 0.0210011 -0.0499396 0.0119308 0.135773 0.871700  4.44801\n 58:     2867.2502: 0.0374784 -0.0465701 0.0140411 0.146417 0.849465  5.34102\n 59:     2865.2784: 0.0416151 -0.0568642 0.0115908 0.133741 0.863377  5.47854\n 60:     2864.2803: 0.0508382 -0.0551564 0.0133502 0.137240 0.863921  5.39588\n 61:     2861.7759: 0.0711833 -0.0514599 0.0116358 0.126101 0.868871  5.59207\n 62:     2861.6890: 0.0720867 -0.0568481 0.0103059 0.127155 0.870034  5.77185\n 63:     2861.6323: 0.0712594 -0.0580540 0.0105727 0.123206 0.871658  5.89046\n 64:     2861.6059: 0.0710100 -0.0558795 0.0112294 0.125022 0.869481  5.92682\n 65:     2861.6004: 0.0709184 -0.0550834 0.0110167 0.124375 0.870072  5.96212\n 66:     2861.6000: 0.0709561 -0.0553609 0.0109915 0.124443 0.870018  5.97670\n 67:     2861.6000: 0.0709474 -0.0553160 0.0109949 0.124443 0.870016  5.97866\n 68:     2861.6000: 0.0709478 -0.0553153 0.0109957 0.124445 0.870013  5.97877\n\nFinal Estimate of the Negative LLH:\n LLH:  -8249.619    norm LLH:  -3.27756 \n           mu           ar1         omega        alpha1         beta1 \n 8.585376e-04 -5.531526e-02  1.610146e-06  1.244449e-01  8.700127e-01 \n        shape \n 5.978770e+00 \n\nR-optimhess Difference Approximated Hessian Matrix:\n                  mu           ar1         omega        alpha1         beta1\nmu     -4.791651e+07 -4.661861e+04 -1.205634e+09 -3.466862e+04 -9.149105e+04\nar1    -4.661861e+04 -2.490882e+03 -1.234074e+06 -8.203053e+00 -9.744031e+01\nomega  -1.205634e+09 -1.234074e+06 -1.703962e+13 -5.515881e+08 -8.452220e+08\nalpha1 -3.466862e+04 -8.203053e+00 -5.515881e+08 -3.611224e+04 -4.469020e+04\nbeta1  -9.149105e+04 -9.744031e+01 -8.452220e+08 -4.469020e+04 -6.270062e+04\nshape  -9.970351e+02  8.557532e-02 -3.050363e+06 -1.832755e+02 -2.340762e+02\n               shape\nmu     -9.970351e+02\nar1     8.557532e-02\nomega  -3.050363e+06\nalpha1 -1.832755e+02\nbeta1  -2.340762e+02\nshape  -2.547431e+00\nattr(,\"time\")\nTime difference of 0.06105161 secs\n\n--- END OF TRACE ---\n\n\nTime to Estimate Parameters:\n Time difference of 0.3197961 secs\n\n# Extract fitted volatility (sigma) from the GARCH model\npredicted_volatility &lt;- djia.g@sigma.t\n\n# Set up a time series index (assuming `djiar` has time index matching `predicted_volatility`)\ndates &lt;- index(djiar)\n\n# Plot the observed returns and predicted volatility\nplot(dates, djiar, type = \"l\", col = \"blue\", ylab = \"Returns and Volatility\", xlab = \"Date\", main = \"DJIA Returns and GARCH(1,1) Predicted Volatility\")\nlines(dates, predicted_volatility, col = \"red\", lty = 2)\n\n# Add a legend\nlegend(\"topright\", legend = c(\"Observed Returns\", \"Predicted Volatility (GARCH)\"), col = c(\"blue\", \"red\"), lty = c(1, 2))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Capítulo 5</span>"
    ]
  },
  {
    "objectID": "cap5.html#aparch-analysis-of-the-djia-returns",
    "href": "cap5.html#aparch-analysis-of-the-djia-returns",
    "title": "3  Capítulo 5",
    "section": "3.3 APARCH Analysis of the DJIA Returns",
    "text": "3.3 APARCH Analysis of the DJIA Returns\n\n3.3.1 Background\nIn this example, we apply an AR-APARCH model to the DJIA returns, as discussed in Example 5.5. Similar to the previous example, an AR(1) term is included in the model to account for the conditional mean. We assume that the error process follows an APARCH(1,1) structure with t-distributed errors to capture asymmetry and heavy tails in the return series. The model equation is:\n[ r_t = _t + y_t ]\nwhere ( _t ) is an AR(1) component, and ( y_t ) follows an APARCH process with conditional variance modeled as specified in Equation (5.53).\n\n3.3.1.1 Model Fitting and Summary\nWe use the fGarch package in R to fit the AR-APARCH(1,1) model to the DJIA returns. The following code performs the fitting and provides a summary of the estimated parameters:\n\nlibrary(xts)\nlibrary(fGarch)\n\n# Calculate daily returns of DJIA\ndjiar &lt;- diff(log(djia$Close))[-1]\n\n# Fit AR(1)-APARCH(1,1) model with t-distributed errors\ndjia.ap &lt;- garchFit(~ arma(1, 0) + aparch(1, 1), data = djiar, cond.dist = \"std\")\n\n\nSeries Initialization:\n ARMA Model:                arma\n Formula Mean:              ~ arma(1, 0)\n GARCH Model:               aparch\n Formula Variance:          ~ aparch(1, 1)\n ARMA Order:                1 0\n Max ARMA Order:            1\n GARCH Order:               1 1\n Max GARCH Order:           1\n Maximum Order:             1\n Conditional Dist:          std\n h.start:                   2\n llh.start:                 1\n Length of Series:          2517\n Recursion Init:            mci\n Series Scale:              0.01210097\n\nParameter Initialization:\n Initial Parameters:          $params\n Limits of Transformations:   $U, $V\n Which Parameters are Fixed?  $includes\n Parameter Matrix:\n                     U           V      params includes\n    mu     -0.15336279   0.1533628  0.01533395     TRUE\n    ar1    -0.99999999   1.0000000 -0.10129752     TRUE\n    omega   0.00000100 100.0000000  0.10000000     TRUE\n    alpha1  0.00000001   1.0000000  0.10000000     TRUE\n    gamma1 -0.99999999   1.0000000  0.10000000     TRUE\n    beta1   0.00000001   1.0000000  0.80000000     TRUE\n    delta   0.00000000   2.0000000  2.00000000     TRUE\n    skew    0.10000000  10.0000000  1.00000000    FALSE\n    shape   1.00000000  10.0000000  4.00000000     TRUE\n Index List of Parameters to be Optimized:\n    mu    ar1  omega alpha1 gamma1  beta1  delta  shape \n     1      2      3      4      5      6      7      9 \n Persistence:                  0.901 \n\n\n--- START OF TRACE ---\nSelected Algorithm: nlminb \n\nR coded nlminb Solver: \n\n  0:     2956.2216: 0.0153339 -0.101298 0.100000 0.100000 0.100000 0.800000  2.00000  4.00000\n  1:     2933.7103: 0.0153349 -0.0994952 0.0816702 0.105086 0.101441 0.794372  1.99989  3.99987\n  2:     2915.7667: 0.0153364 -0.0969033 0.0659019 0.116672 0.103734 0.795785  2.00000  3.99997\n  3:     2868.4755: 0.0153445 -0.0848310 0.0240071 0.174769 0.115713 0.826263  2.00000  4.00127\n  4:     2866.0067: 0.0153484 -0.0806140 0.0223751 0.179103 0.121376 0.835430  2.00000  4.00180\n  5:     2865.7487: 0.0153525 -0.0768014 0.0131222 0.176106 0.127212 0.838921  1.99992  4.00228\n  6:     2863.1420: 0.0153538 -0.0756613 0.0180358 0.176968 0.129016 0.841888  2.00000  4.00245\n  7:     2856.2449: 0.0153875 -0.0476167 0.00965957 0.170079 0.175758 0.860641  1.99995  4.00607\n  8:     2853.4108: 0.0154249 -0.0295659 0.0252436 0.165440 0.224654 0.839180  1.99938  4.00936\n  9:     2853.0448: 0.0154257 -0.0299884 0.0155240 0.163926 0.225784 0.836602  1.99923  4.00941\n 10:     2850.4568: 0.0154262 -0.0301237 0.0197886 0.165257 0.226344 0.839033  1.99934  4.00951\n 11:     2849.7888: 0.0154284 -0.0309518 0.0166941 0.166172 0.229095 0.841761  1.99938  4.00981\n 12:     2849.3808: 0.0154318 -0.0322155 0.0188338 0.167018 0.233146 0.843406  1.99940  4.01023\n 13:     2848.6297: 0.0154356 -0.0334350 0.0170783 0.166875 0.237702 0.842613  1.99931  4.01065\n 14:     2848.2726: 0.0154392 -0.0343915 0.0177679 0.167228 0.241904 0.845217  1.99934  4.01111\n 15:     2847.6118: 0.0154433 -0.0353050 0.0161095 0.167003 0.246509 0.844166  1.99923  4.01155\n 16:     2839.6580: 0.0155653 -0.0553493 0.0222431 0.178380 0.380319 0.824116  1.99673  4.02506\n 17:     2839.3512: 0.0155658 -0.0550968 0.0204751 0.177743 0.380646 0.823994  1.99667  4.02511\n 18:     2838.9545: 0.0155699 -0.0530330 0.0209096 0.175844 0.383429 0.828959  1.99653  4.02564\n 19:     2838.4453: 0.0155822 -0.0490947 0.0190161 0.175891 0.387313 0.827244  1.99538  4.02695\n 20:     2838.2004: 0.0155983 -0.0451962 0.0202650 0.176410 0.391417 0.827097  1.99373  4.02871\n 21:     2837.9655: 0.0156258 -0.0427583 0.0191101 0.176071 0.394484 0.826442  1.99035  4.03170\n 22:     2837.7164: 0.0156586 -0.0433600 0.0199725 0.175167 0.395086 0.827962  1.98601  4.03528\n 23:     2837.4877: 0.0156899 -0.0444502 0.0188067 0.173444 0.395339 0.829067  1.98177  4.03873\n 24:     2837.2542: 0.0157227 -0.0444858 0.0196845 0.172775 0.396371 0.830254  1.97741  4.04241\n 25:     2837.0243: 0.0157544 -0.0436348 0.0187730 0.171889 0.398204 0.830412  1.97322  4.04605\n 26:     2836.8012: 0.0157867 -0.0431291 0.0196235 0.171422 0.399701 0.831316  1.96895  4.04979\n 27:     2836.5848: 0.0158187 -0.0432528 0.0186828 0.170271 0.400698 0.831832  1.96461  4.05354\n 28:     2836.3739: 0.0158508 -0.0434055 0.0194501 0.169589 0.401625 0.832972  1.96028  4.05734\n 29:     2836.1649: 0.0158827 -0.0431931 0.0185802 0.168628 0.402869 0.833293  1.95598  4.06117\n 30:     2835.9597: 0.0159145 -0.0428368 0.0193553 0.168170 0.404207 0.834156  1.95172  4.06504\n 31:     2835.7585: 0.0159462 -0.0426654 0.0185188 0.167252 0.405404 0.834462  1.94744  4.06892\n 32:     2835.5621: 0.0159779 -0.0426467 0.0192452 0.166709 0.406444 0.835427  1.94316  4.07284\n 33:     2835.3683: 0.0160095 -0.0425704 0.0184359 0.165808 0.407541 0.835744  1.93888  4.07678\n 34:     2835.1779: 0.0160411 -0.0423779 0.0191523 0.165365 0.408710 0.836588  1.93464  4.08076\n 35:     2834.9901: 0.0160726 -0.0421938 0.0183829 0.164555 0.409882 0.836832  1.93040  4.08474\n 36:     2834.8061: 0.0161042 -0.0420878 0.0190714 0.164114 0.410966 0.837674  1.92617  4.08876\n 37:     2834.6246: 0.0161357 -0.0420095 0.0183222 0.163312 0.412035 0.837939  1.92194  4.09279\n 38:     2834.4462: 0.0161673 -0.0418854 0.0189920 0.162910 0.413121 0.838736  1.91773  4.09685\n 39:     2834.2698: 0.0161987 -0.0417390 0.0182750 0.162177 0.414233 0.838949  1.91352  4.10092\n 40:     2834.0965: 0.0162303 -0.0416151 0.0189257 0.161805 0.415308 0.839711  1.90934  4.10501\n 41:     2833.9253: 0.0162618 -0.0415237 0.0182290 0.161092 0.416362 0.839927  1.90514  4.10911\n 42:     2833.7569: 0.0162934 -0.0414219 0.0188604 0.160741 0.417408 0.840667  1.90097  4.11324\n 43:     2833.5901: 0.0163250 -0.0413048 0.0181889 0.160075 0.418472 0.840852  1.89680  4.11737\n 44:     2833.4261: 0.0163566 -0.0411882 0.0188048 0.159756 0.419520 0.841555  1.89265  4.12152\n 45:     2833.2636: 0.0163883 -0.0410937 0.0181531 0.159117 0.420555 0.841733  1.88849  4.12568\n 46:     2833.1037: 0.0164201 -0.0410006 0.0187518 0.158815 0.421575 0.842418  1.88435  4.12986\n 47:     2832.9452: 0.0164519 -0.0409017 0.0181207 0.158211 0.422604 0.842576  1.88021  4.13404\n 48:     2832.7890: 0.0164838 -0.0407973 0.0187056 0.157937 0.423625 0.843229  1.87609  4.13824\n 49:     2832.6341: 0.0165157 -0.0407067 0.0180929 0.157360 0.424638 0.843376  1.87196  4.14245\n 50:     2832.4815: 0.0165478 -0.0406213 0.0186628 0.157101 0.425636 0.844012  1.86786  4.14667\n 51:     2832.3300: 0.0165799 -0.0405346 0.0180677 0.156553 0.426639 0.844146  1.86374  4.15089\n 52:     2832.1806: 0.0166122 -0.0404422 0.0186253 0.156317 0.427635 0.844755  1.85965  4.15513\n 53:     2832.0323: 0.0166446 -0.0403594 0.0180468 0.155794 0.428627 0.844877  1.85556  4.15937\n 54:     2831.8860: 0.0166771 -0.0402797 0.0185914 0.155574 0.429607 0.845469  1.85148  4.16362\n 55:     2831.7406: 0.0167096 -0.0402025 0.0180284 0.155074 0.430588 0.845580  1.84740  4.16787\n 56:     2831.5971: 0.0167424 -0.0401200 0.0185619 0.154873 0.431564 0.846150  1.84334  4.17214\n 57:     2823.2275: 0.0241723 -0.0178143 0.0279421 0.154694 0.570032 0.852884 0.917653  5.13851\n 58:     2823.0077: 0.0243118 -0.0209096 0.0315367 0.155146 0.569922 0.857579 0.900545  5.15526\n 59:     2820.5079: 0.0243219 -0.0208801 0.0294576 0.153786 0.569402 0.856246 0.913322  5.15707\n 60:     2820.0209: 0.0243261 -0.0259732 0.0222170 0.153394 0.574190 0.864662 0.914968  5.15741\n 61:     2819.2340: 0.0243310 -0.0260678 0.0232473 0.153113 0.573853 0.865714 0.928086  5.15821\n 62:     2814.8421: 0.0250357 -0.0398787 0.0179842 0.132129 0.560768 0.879198  1.17994  5.25066\n 63:     2814.8331: 0.0254014 -0.0459558 0.0176973 0.127988 0.560005 0.881149  1.15004  5.28917\n 64:     2814.4735: 0.0257755 -0.0467011 0.0185883 0.127078 0.563492 0.882539  1.14177  5.29761\n 65:     2814.2272: 0.0257944 -0.0428649 0.0182816 0.128524 0.566955 0.880937  1.15745  5.27588\n 66:     2813.7698: 0.0261858 -0.0419618 0.0205550 0.126865 0.575104 0.878813  1.16041  5.27253\n 67:     2813.4645: 0.0265757 -0.0420537 0.0199896 0.126314 0.578671 0.878986  1.15776  5.28170\n 68:     2812.8046: 0.0272480 -0.0320793 0.0193600 0.130919 0.591671 0.876133  1.19909  5.24647\n 69:     2807.7324: 0.0427119 -0.0513132 0.0210760 0.111811 0.708844 0.891478  1.07619  5.77275\n 70:     2801.4712: 0.0560713 -0.0740097 0.0208609 0.114749 0.814103 0.879998  1.09695  6.51607\n 71:     2800.2814: 0.0553548 -0.0644686 0.0202525 0.107577 0.852183 0.886684  1.07015  6.48728\n 72:     2799.8245: 0.0532178 -0.0594050 0.0214275 0.105320 0.890711 0.889987  1.07690  6.46536\n 73:     2798.3999: 0.0510334 -0.0569062 0.0207359 0.103398 0.923747 0.890912  1.06938  6.47024\n 74:     2796.9941: 0.0438258 -0.0476311 0.0199962 0.0978223  1.00000 0.895386  1.07274  6.73868\n 75:     2796.8730: 0.0433183 -0.0483913 0.0202190 0.0982598  1.00000 0.894017  1.07497  7.09290\n 76:     2796.8639: 0.0434729 -0.0476753 0.0199892 0.0976425  1.00000 0.893818  1.09162  7.27643\n 77:     2796.8505: 0.0433533 -0.0483650 0.0202096 0.0977215  1.00000 0.894083  1.07973  7.27834\n 78:     2796.8484: 0.0433224 -0.0483607 0.0202113 0.0980776  1.00000 0.894201  1.07448  7.26945\n 79:     2796.8473: 0.0432669 -0.0482305 0.0202565 0.0981140  1.00000 0.894400  1.07069  7.27836\n 80:     2796.8472: 0.0432528 -0.0481818 0.0202574 0.0980857  1.00000 0.894466  1.07018  7.28534\n 81:     2796.8472: 0.0432523 -0.0481871 0.0202604 0.0980913  1.00000 0.894455  1.07022  7.28569\n 82:     2796.8472: 0.0432531 -0.0481833 0.0202594 0.0980894  1.00000 0.894456  1.07024  7.28577\n\nFinal Estimate of the Negative LLH:\n LLH:  -8311.583    norm LLH:  -3.302178 \n           mu           ar1         omega        alpha1        gamma1 \n 0.0005234050 -0.0481832641  0.0001798009  0.0980893747  0.9999999900 \n        beta1         delta         shape \n 0.8944563711  1.0702355865  7.2857704887 \n\nR-optimhess Difference Approximated Hessian Matrix:\n                  mu           ar1         omega        alpha1        gamma1\nmu      -92572375.49 -1.304310e+05 -6.613022e+08 -2.435867e+06 -1.277035e+05\nar1       -130430.97 -2.960609e+03 -7.708017e+05 -1.492684e+03 -7.809006e+01\nomega  -661302169.81 -7.708017e+05 -9.933158e+09 -3.284973e+07 -1.721832e+06\nalpha1   -2435867.05 -1.492684e+03 -3.284973e+07 -1.662171e+05 -8.715935e+03\ngamma1    -127703.52 -7.809006e+01 -1.721832e+06 -8.715935e+03 -9.620990e+03\nbeta1    -3642690.42 -3.791544e+03 -5.191605e+07 -2.185958e+05 -1.146447e+04\ndelta     -248101.20 -2.643135e+02 -3.568338e+06 -1.497208e+04 -7.831015e+02\nshape       -4448.78 -2.850922e+00 -4.321048e+04 -2.197835e+02 -1.153887e+01\n               beta1         delta         shape\nmu      -3642690.416 -2.481012e+05  -4448.780252\nar1        -3791.544 -2.643135e+02     -2.850922\nomega  -51916048.337 -3.568338e+06 -43210.482623\nalpha1   -218595.807 -1.497208e+04   -219.783489\ngamma1    -11464.468 -7.831015e+02    -11.538865\nbeta1    -320129.731 -2.153576e+04   -285.455040\ndelta     -21535.759 -1.520674e+03    -19.343988\nshape       -285.455 -1.934399e+01     -1.118540\nattr(,\"time\")\nTime difference of 0.1125531 secs\n\n--- END OF TRACE ---\n\n\nTime to Estimate Parameters:\n Time difference of 0.4962823 secs\n\nsummary(djia.ap)\n\n\nTitle:\n GARCH Modelling \n\nCall:\n garchFit(formula = ~arma(1, 0) + aparch(1, 1), data = djiar, \n    cond.dist = \"std\") \n\nMean and Variance Equation:\n data ~ arma(1, 0) + aparch(1, 1)\n&lt;environment: 0x55f1676901e8&gt;\n [data = djiar]\n\nConditional Distribution:\n std \n\nCoefficient(s):\n        mu         ar1       omega      alpha1      gamma1       beta1  \n 0.0005234  -0.0481833   0.0001798   0.0980894   1.0000000   0.8944564  \n     delta       shape  \n 1.0702356   7.2857705  \n\nStd. Errors:\n based on Hessian \n\nError Analysis:\n         Estimate  Std. Error  t value Pr(&gt;|t|)    \nmu      5.234e-04   1.525e-04    3.433 0.000598 ***\nar1    -4.818e-02   1.934e-02   -2.491 0.012729 *  \nomega   1.798e-04   3.443e-05    5.222 1.77e-07 ***\nalpha1  9.809e-02   1.030e-02    9.525  &lt; 2e-16 ***\ngamma1  1.000e+00   1.045e-02   95.728  &lt; 2e-16 ***\nbeta1   8.945e-01   1.049e-02   85.279  &lt; 2e-16 ***\ndelta   1.070e+00   1.350e-01    7.928 2.22e-15 ***\nshape   7.286e+00   1.123e+00    6.490 8.61e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nLog Likelihood:\n 8311.583    normalized:  3.302178 \n\nDescription:\n Mon Nov 18 16:05:01 2024 by user:  \n\n\nStandardised Residuals Tests:\n                                 Statistic     p-Value\n Jarque-Bera Test   R    Chi^2  245.156078 0.000000000\n Shapiro-Wilk Test  R    W        0.983058 0.000000000\n Ljung-Box Test     R    Q(10)   15.595870 0.111800290\n Ljung-Box Test     R    Q(15)   26.450980 0.033541324\n Ljung-Box Test     R    Q(20)   30.170758 0.067133620\n Ljung-Box Test     R^2  Q(10)   19.176843 0.038073151\n Ljung-Box Test     R^2  Q(15)   30.466591 0.010345882\n Ljung-Box Test     R^2  Q(20)   35.364460 0.018246902\n LM Arch Test       R    TR^2    29.577276 0.003231735\n\nInformation Criterion Statistics:\n      AIC       BIC       SIC      HQIC \n-6.598000 -6.579468 -6.598020 -6.591274 \n\n\n\n\n3.3.1.2 Parameter Estimates\nThe AR(1) coefficient (_1) is -0.04818, while the APARCH parameters (_1), (_1), and () indicate the model captures asymmetry and persistence in volatility.\n\n\n3.3.1.3 Residual Diagnostics\nSeveral tests were performed to check the residuals for independence and normality:\n\nLjung-Box Test:\n\nResiduals ([R]): (Q(10) = 15.71), with a p-value of 0.108, suggesting no significant autocorrelation in the residuals.\nSquared Residuals ([R^2]): (Q(10) = 16.87), with a p-value of 0.077, indicating no remaining ARCH effects.\n\n\n\n\n3.3.1.4 Predicted Volatility\nThe predicted volatility from the APARCH model differs from the GARCH model but displays similar volatility clustering patterns. To compare, we plot the observed returns and the one-step-ahead predicted volatility.\n\n# Plot observed returns and APARCH predicted volatility\ndates &lt;- index(djiar)\npredicted_volatility_aparch &lt;- djia.ap@sigma.t\n\nplot(dates, djiar, type = \"l\", col = \"blue\", ylab = \"Returns and Volatility\", xlab = \"Date\", main = \"DJIA Returns and APARCH(1,1) Predicted Volatility\")\nlines(dates, predicted_volatility_aparch, col = \"green\", lty = 2)\n\n# Add a legend\nlegend(\"topright\", legend = c(\"Observed Returns\", \"Predicted Volatility (APARCH)\"), col = c(\"blue\", \"green\"), lty = c(1, 2))\n\n\n\n\n\n\n\n\nThis plot compares the daily returns with the APARCH model’s predicted volatility, highlighting volatility clustering in the DJIA returns over time.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Capítulo 5</span>"
    ]
  }
]